<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="Use a Lance Image Dataset to train a Image Classification model" /><meta property="og:locale" content="en_US" /><meta name="description" content="This post gives a detailed view on how you can use the Lance Image Dataset to train a classification model" /><meta property="og:description" content="This post gives a detailed view on how you can use the Lance Image Dataset to train a classification model" /><link rel="canonical" href="http://localhost:4000/2024/04/10/use-lance-image-dataset-to-train-a-image-classification-model" /><meta property="og:url" content="http://localhost:4000/2024/04/10/use-lance-image-dataset-to-train-a-image-classification-model" /><meta property="og:site_name" content="Blixxi Labs" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-04-10T00:00:00+05:30" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Use a Lance Image Dataset to train a Image Classification model" /><meta name="twitter:site" content="@PinakaX" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-04-10T00:00:00+05:30","datePublished":"2024-04-10T00:00:00+05:30","description":"This post gives a detailed view on how you can use the Lance Image Dataset to train a classification model","headline":"Use a Lance Image Dataset to train a Image Classification model","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/04/10/use-lance-image-dataset-to-train-a-image-classification-model"},"url":"http://localhost:4000/2024/04/10/use-lance-image-dataset-to-train-a-image-classification-model"}</script><title> Use a Lance Image Dataset to train a Image Classification model - Blixxi Labs</title><link rel="shortcut icon" href="/favicon.png"><link rel="alternate" type="application/atom+xml" title="Blixxi Labs" href="/atom.xml"><link rel="alternate" type="application/json" title="Blixxi Labs" href="http://localhost:4000/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml" /><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.5;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#f5f5f5;max-width:100%;overflow-x:auto}code{padding:.1rem;font-size:.85rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%;background:none;display:block;margin:auto}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}.post ol,.project ul,.post ol,.post ul{padding-left:1rem}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}@media print{.no-print,.no-print *{display:none !important}}.back-to-top{position:fixed;bottom:20px;right:20px;background-color:#fff;color:#000;padding:10px;text-decoration:none;border-radius:5px;display:block;margin-right:20%}</style></head><body><main><header aria-hidden="true" class="no-print"> <!--<h1 class="logo">Blixxi Labs</h1>--><nav role="navigation" aria-hidden="true"><ul><li><a href="/" >Home</a></li><li><a href="/about" >About</a></li><li><a href="/contact" >Contact</a></li></ul></nav></header><section class="post"><h1>Use a Lance Image Dataset to train a Image Classification model</h1><p><img src="https://raw.githubusercontent.com/vipul-maheshwari/vipul-maheshwari.github.io/15418ff16a807a748797dba2983ec39990ea85d0/images/training-with-lance-data/less-time.png" alt="image" /></p><p>In a <a href="https://vipul-maheshwari.github.io/2024/04/09/convert-any-image-dataset-to-lance">previous</a> post, I showed you how you can convert any Image Dataset to Lance format for faster retrieval and faster I/O operations. But can we use the same Lance formatted image dataset to train a image classification model? Well here it comes…</p><h3 id="lance-a-saga-for-efficient-image-datasets">LANCE: A Saga for Efficient Image Datasets</h3><p>Convolutional Neural Networks (CNNs) have become the go-to architecture for a wide range of image-related tasks, including image classification, object detection, and semantic segmentation. The ability of CNNs to automatically learn relevant features from the input data, combined with their strong performance on complex visual tasks, makes them a natural choice for image classification models.</p><p>When working with large-scale image datasets, the management and processing of data can become a significant challenge. Traditional file formats like JPEG and PNG, while widely used, are not optimized for the unique requirements of machine learning workflows. This is where the LANCE (Lightweight Annotated Neural Classification Encoding) format shines, providing a game-changing solution for managing and leveraging image datasets.</p><p>The LANCE format offers several key advantages that make it a powerful choice for machine learning applications:</p><ol><li><p>Columnar Storage: LANCE stores data in a compressed columnar format, enabling efficient storage, fast data loading, and quick random access to subsets of the data. This is particularly beneficial when working with large-scale image datasets.</p></li><li><p>Multimodal Data Handling: LANCE is designed to handle diverse data types, including images, text, and numerical data, within a unified format. This flexibility is a game-changer in machine learning pipelines, where different modalities of data often need to be processed together.</p></li><li><p>Data Persistence and Privacy: LANCE maintains data on disk, ensuring that the data persists through system failures and doesn’t need to be constantly transferred over a network. This also enhances data privacy and security, as the data can be stored and accessed locally without relying on external data sources.</p></li></ol><h3 id="integrating-lance-and-convolutional-neural-networks">Integrating LANCE and Convolutional Neural Networks</h3><p>The structured and efficient data organization of the LANCE format allows for seamless integration with Convolutional Neural Network (CNN) architectures, streamlining the data loading and preprocessing steps. By leveraging the LANCE format, you can overcome the challenges of working with large-scale image datasets and focus more on the core aspects of model development and optimization.</p><p>In our previous article, we discussed the process of converting various image datasets, such as CINIC-10 and mini-ImageNet, into the LANCE format. Now, we will explore how we can utilize this LANCE-formatted data to train a CNN-based image classification model.</p><p>Before diving into the model training, let’s take a closer look at the structure of the LANCE-formatted data we created earlier. Referring to the script from the previous article, we can see how the LANCE dataset is organized:</p><pre><code class="language-python">import os
import pandas as pd
import pyarrow as pa
import lance
import time
from tqdm import tqdm

def process_images(split):
    # Get the current directory path
    images_folder = os.path.join("cinic", split)

    # Define schema for RecordBatch
    schema = pa.schema([('image', pa.binary()), 
                        ('filename', pa.string()), 
                        ('label', pa.string()), 
                        ('split', pa.string())])

    # Iterate over the categories within each data type
    for label in os.listdir(images_folder):
        label_folder = os.path.join(images_folder, label)
        
        # Iterate over the images within each label
        for filename in tqdm(os.listdir(label_folder), desc=f"Processing {split} - {label}"):
            # Construct the full path to the image
            image_path = os.path.join(label_folder, filename)

            # Read and convert the image to a binary format
            with open(image_path, 'rb') as f:
                binary_data = f.read()

            image_array = pa.array([binary_data], type=pa.binary())
            filename_array = pa.array([filename], type=pa.string())
            label_array = pa.array([label], type=pa.string())
            split_array = pa.array([split], type=pa.string())

            # Yield RecordBatch for each image
            yield pa.RecordBatch.from_arrays(
                [image_array, filename_array, label_array, split_array],
                schema=schema
            )

# Function to write PyArrow Table to Lance dataset
def write_to_lance():
    # Create an empty RecordBatchIterator
    schema = pa.schema([
        pa.field("image", pa.binary()),
        pa.field("filename", pa.string()),
        pa.field("label", pa.string()),
        pa.field("split", pa.string())
    ])

    # Specify the path where you want to save the Lance files
    images_folder = "cinic"
    
    for split in ['train', 'test', 'val']:
        lance_file_path = os.path.join(images_folder, f"cinic_{split}.lance")
        
        reader = pa.RecordBatchReader.from_batches(schema, process_images(split))
        lance.write_dataset(
            reader,
            lance_file_path,
            schema,
        )

def loading_into_pandas():
    # Load Lance files from the same folder
    current_dir = os.getcwd()
    print(current_dir)
    images_folder = os.path.join(current_dir, "cinic")
    
    data_frames = {}  # Dictionary to store DataFrames for each data type
    
    for split in ['test', 'train', 'val']:
        uri = os.path.join(images_folder, f"cinic_{split}.lance")

        ds = lance.dataset(uri)

        # Accumulate data from batches into a list
        data = []
        for batch in tqdm(ds.to_batches(columns=["image", "filename", "label", "split"], batch_size=10), desc=f"Loading {split} batches"):
            tbl = batch.to_pandas()
            data.append(tbl)

        # Concatenate all DataFrames into a single DataFrame
        df = pd.concat(data, ignore_index=True)
        
        # Store the DataFrame in the dictionary
        data_frames[split] = df
        
        print(f"Pandas DataFrame for {split} is ready")
        print("Total Rows: ", df.shape[0])
    
    return data_frames


if __name__ == "__main__":
    start = time.time()
    write_to_lance()
    data_frames = loading_into_pandas()
    end = time.time()
    print(f"Time(sec): {end - start}")
</code></pre><p>The script above creates LANCE-formatted files for the training, testing, and validation sets of the CINIC-10 dataset</p><pre><code class="language-python"># Load the LANCE-formatted datasets
train = data_frames['train']
test = data_frames['test'] 
val = data_frames['val']
</code></pre><p>and The <code>data_frames</code> dictionary contains the Pandas DataFrames for the training, testing, and validation sets, where each DataFrame has the following structure:</p><pre><code class="language-markdown">   image                                              filename                    label    split
0  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  n02130308_1836.png           cat     train
1  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  cifar10-train-21103.png      cat     train
2  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  cifar10-train-44957.png      cat     train
3  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  n02129604_14997.png          cat     train
4  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  n02123045_1463.png           cat     train
</code></pre><p>Now that we have the LANCE-formatted data ready, we can use it to train a Convolutional Neural Network (CNN) for image classification. To do this, we’ll first need to create PyTorch Dataset and DataLoader objects from the LANCE-formatted Pandas DataFrames.</p><h2 id="load-the-lance-files-to-create-the-dataloaders">Load the lance files to create the dataloaders</h2><p>When working with LANCE-formatted image data, we need to consider that the images are stored in a binary format within the Pandas DataFrame. To use this data with a Convolutional Neural Network (CNN), we need to convert the binary data back into a format that the CNN can process, such as PIL Image objects. Here’s how we we’ll do that:</p><ol><li>Retrieve the binary image data: The image data is stored in binary format within the Pandas DataFrame. We’ll need to extract this binary data for each image.</li><li>Convert to PIL Image: Once we have the binary data, we’ll convert it into a PIL Image object. This will give us a readable image format that we can work with.</li><li>Handle grayscale images: Some of the images might be in grayscale mode. We’ll need to convert these to RGB format so they’re compatible with a CNN that expects 3-channel color images.</li><li>Apply transformations: Before feeding the images to the CNN, we may need to apply some transformations, like resizing or normalization. We can do this using the provided transform function.</li><li>Determine the labels: Each image has a label or class associated with it. We’ll look up the class index for the image’s label in the provided list of classes.</li><li>Return the data: Finally, we’ll return the transformed image and its corresponding label, which can be used to train the CNN model.</li></ol><p>To accomplish this, we’ll create a custom PyTorch Dataset class that can handle the all the heavy lifting and give us this sweet dataset to work with</p><pre><code class="language-python">from torch.utils import data
from PIL import Image
import io

class CustomImageDataset(data.Dataset):
    def __init__(self, df, classes, transform=None):
        self.df = df
        self.classes = classes
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_data = self.df.iloc[idx]['image']
        img = Image.open(io.BytesIO(img_data))

        # Convert grayscale images to RGB
        if img.mode != 'RGB':
            img = img.convert('RGB')

        if self.transform:
            img = self.transform(img)

        label = self.classes.index(self.df.iloc[idx]['label'])
        return img, label
</code></pre><p>This custom dataset class handles all the necessary steps to prepare our LANCE-formatted dataframe for use with a CNN model. By using this class, you can easily integrate the LANCE data into your PyTorch-based training pipeline. oh boy, we are ready to roll for training our model.</p><h3 id="training-a-cnn">Training a CNN</h3><p>So we have written our custom dataset class, we will just import it in our main CNN script and utilize it’s functionalities, as it’s pretty easy now</p><p>First we will load our lance files, then we will convert those lance files to our pandas dataframe objects and then finally the customimagedataset to utilize the binary data of the images to give us this image dataset..</p><p>That’s it, other than that, it’s simple CNN network doing the training..</p><pre><code class="language-python">import torch 
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from custom_dataset import CustomImageDataset
import pandas as pd
import matplotlib.pyplot as plt
import lance
from tqdm import tqdm
import torch.optim as optim

# Define the classes
classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck')

# Define the image transformations
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

def loading_into_pandas(uri):
    ds = lance.dataset(uri)

    # Accumulate data from batches into a list
    data = []
    for batch in tqdm(ds.to_batches(columns=["image", "filename", "label", "split"], batch_size=10), desc="Loading batches"):
        tbl = batch.to_pandas()
        data.append(tbl)

    # Concatenate all DataFrames into a single DataFrame
    df = pd.concat(data, ignore_index=True)
    print("Pandas DataFrame is ready")
    print("Total Rows: ", df.shape[0])
    return df

def train_model(train_loader, model, criterion, optimizer, device, num_epochs=10):
    model.to(device)  # Move model to the specified device
    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, data in enumerate(train_loader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data[0].to(device), data[1].to(device)  # Move data to the specified device

            # zero the parameter gradients
            optimizer.zero_grad()
            
            # forward + backward + optimize
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if i % 64 == 63:  # Print every 64 mini-batches (batch size)
                print(f'[{epoch + 1}, {i + 1:2d}] loss: {running_loss / 64:.3f}')
                running_loss = 0.0

    print('Finished Training')

def main():
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("MPS Device:", device)
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print("Device:", device)    

    # Load datasets
    training_df = loading_into_pandas('cinic/cinic_train.lance')
    testing_df = loading_into_pandas('cinic/cinic_test.lance')
    validation_df = loading_into_pandas('cinic/cinic_val.lance')

    # Create datasets
    train_dataset = CustomImageDataset(training_df, classes, transform=transform)
    test_dataset = CustomImageDataset(testing_df, classes, transform=transform)
    val_dataset = CustomImageDataset(validation_df, classes, transform=transform)

    # Create data loaders
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)

    # Define the neural network
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5) # 3 input channels, 6 output channels, 5x5 kernel
            self.pool = nn.MaxPool2d(2, 2) # 2x2 pooling
            self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel
            self.fc1 = nn.Linear(16 * 5 * 5, 120) 
            self.fc2 = nn.Linear(120, 84) 
            self.fc3 = nn.Linear(84, 10) # There are 10 classes

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1) # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x

    # Instantiate the model
    net = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

    # Train the model
    train_model(train_loader, net, criterion, optimizer, device, num_epochs=10)

    PATH = './cinic_net.pth'
    torch.save(net.state_dict(), PATH)

    net = Net()
    net.load_state_dict(torch.load(PATH))

    correct = 0
    total = 0

    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            # calculate outputs by running images through the network
            outputs = net(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    # Calculate accuracy
    accuracy = 100 * correct / total
    print('Accuracy of the network on the test images: %.2f %%' % accuracy)

if __name__ == "__main__":
    main()

</code></pre><p>We’ve just wrapped up training a Convolutional Neural Network (CNN) with a dataset of lance images with just a single script.</p><p>And if you are Curious about why Lance-backed training outperforms our vanilla approaches? I’ve got a <a href="https://wandb.ai/vipulmaheshwari/cinic-10/reports/CINIC-10-CNN-Training-Showdown-Lance-Vs-Vanilla--Vmlldzo3NTQxMTY5?accessToken=k2tk2e7u6x4ya5vivhtzieoh3lzm25e5z1inqhmaue41prct5ca65xufi3eznhj4">report</a> for you, showcasing how Lance-backed training excels in terms of I/O operations and training epochs compared to traditional methods.</p><p>By the way, you can dive into various deep learning techniques that utilize lance-formatted data on this <a href="https://github.com/lancedb/lance-deeplearning-recipes">repository</a></p><span class="meta"><time datetime="2024-04-10T00:00:00+05:30">April 10, 2024</time></span></section><!-- --- layout: default ---<section class="post"><h2>Use a Lance Image Dataset to train a Image Classification model</h2><p><img src="https://raw.githubusercontent.com/vipul-maheshwari/vipul-maheshwari.github.io/15418ff16a807a748797dba2983ec39990ea85d0/images/training-with-lance-data/less-time.png" alt="image" /></p><p>In a <a href="https://vipul-maheshwari.github.io/2024/04/09/convert-any-image-dataset-to-lance">previous</a> post, I showed you how you can convert any Image Dataset to Lance format for faster retrieval and faster I/O operations. But can we use the same Lance formatted image dataset to train a image classification model? Well here it comes…</p><h3 id="lance-a-saga-for-efficient-image-datasets">LANCE: A Saga for Efficient Image Datasets</h3><p>Convolutional Neural Networks (CNNs) have become the go-to architecture for a wide range of image-related tasks, including image classification, object detection, and semantic segmentation. The ability of CNNs to automatically learn relevant features from the input data, combined with their strong performance on complex visual tasks, makes them a natural choice for image classification models.</p><p>When working with large-scale image datasets, the management and processing of data can become a significant challenge. Traditional file formats like JPEG and PNG, while widely used, are not optimized for the unique requirements of machine learning workflows. This is where the LANCE (Lightweight Annotated Neural Classification Encoding) format shines, providing a game-changing solution for managing and leveraging image datasets.</p><p>The LANCE format offers several key advantages that make it a powerful choice for machine learning applications:</p><ol><li><p>Columnar Storage: LANCE stores data in a compressed columnar format, enabling efficient storage, fast data loading, and quick random access to subsets of the data. This is particularly beneficial when working with large-scale image datasets.</p></li><li><p>Multimodal Data Handling: LANCE is designed to handle diverse data types, including images, text, and numerical data, within a unified format. This flexibility is a game-changer in machine learning pipelines, where different modalities of data often need to be processed together.</p></li><li><p>Data Persistence and Privacy: LANCE maintains data on disk, ensuring that the data persists through system failures and doesn’t need to be constantly transferred over a network. This also enhances data privacy and security, as the data can be stored and accessed locally without relying on external data sources.</p></li></ol><h3 id="integrating-lance-and-convolutional-neural-networks">Integrating LANCE and Convolutional Neural Networks</h3><p>The structured and efficient data organization of the LANCE format allows for seamless integration with Convolutional Neural Network (CNN) architectures, streamlining the data loading and preprocessing steps. By leveraging the LANCE format, you can overcome the challenges of working with large-scale image datasets and focus more on the core aspects of model development and optimization.</p><p>In our previous article, we discussed the process of converting various image datasets, such as CINIC-10 and mini-ImageNet, into the LANCE format. Now, we will explore how we can utilize this LANCE-formatted data to train a CNN-based image classification model.</p><p>Before diving into the model training, let’s take a closer look at the structure of the LANCE-formatted data we created earlier. Referring to the script from the previous article, we can see how the LANCE dataset is organized:</p><pre><code class="language-python">import os
import pandas as pd
import pyarrow as pa
import lance
import time
from tqdm import tqdm

def process_images(split):
    # Get the current directory path
    images_folder = os.path.join("cinic", split)

    # Define schema for RecordBatch
    schema = pa.schema([('image', pa.binary()), 
                        ('filename', pa.string()), 
                        ('label', pa.string()), 
                        ('split', pa.string())])

    # Iterate over the categories within each data type
    for label in os.listdir(images_folder):
        label_folder = os.path.join(images_folder, label)
        
        # Iterate over the images within each label
        for filename in tqdm(os.listdir(label_folder), desc=f"Processing {split} - {label}"):
            # Construct the full path to the image
            image_path = os.path.join(label_folder, filename)

            # Read and convert the image to a binary format
            with open(image_path, 'rb') as f:
                binary_data = f.read()

            image_array = pa.array([binary_data], type=pa.binary())
            filename_array = pa.array([filename], type=pa.string())
            label_array = pa.array([label], type=pa.string())
            split_array = pa.array([split], type=pa.string())

            # Yield RecordBatch for each image
            yield pa.RecordBatch.from_arrays(
                [image_array, filename_array, label_array, split_array],
                schema=schema
            )

# Function to write PyArrow Table to Lance dataset
def write_to_lance():
    # Create an empty RecordBatchIterator
    schema = pa.schema([
        pa.field("image", pa.binary()),
        pa.field("filename", pa.string()),
        pa.field("label", pa.string()),
        pa.field("split", pa.string())
    ])

    # Specify the path where you want to save the Lance files
    images_folder = "cinic"
    
    for split in ['train', 'test', 'val']:
        lance_file_path = os.path.join(images_folder, f"cinic_{split}.lance")
        
        reader = pa.RecordBatchReader.from_batches(schema, process_images(split))
        lance.write_dataset(
            reader,
            lance_file_path,
            schema,
        )

def loading_into_pandas():
    # Load Lance files from the same folder
    current_dir = os.getcwd()
    print(current_dir)
    images_folder = os.path.join(current_dir, "cinic")
    
    data_frames = {}  # Dictionary to store DataFrames for each data type
    
    for split in ['test', 'train', 'val']:
        uri = os.path.join(images_folder, f"cinic_{split}.lance")

        ds = lance.dataset(uri)

        # Accumulate data from batches into a list
        data = []
        for batch in tqdm(ds.to_batches(columns=["image", "filename", "label", "split"], batch_size=10), desc=f"Loading {split} batches"):
            tbl = batch.to_pandas()
            data.append(tbl)

        # Concatenate all DataFrames into a single DataFrame
        df = pd.concat(data, ignore_index=True)
        
        # Store the DataFrame in the dictionary
        data_frames[split] = df
        
        print(f"Pandas DataFrame for {split} is ready")
        print("Total Rows: ", df.shape[0])
    
    return data_frames


if __name__ == "__main__":
    start = time.time()
    write_to_lance()
    data_frames = loading_into_pandas()
    end = time.time()
    print(f"Time(sec): {end - start}")
</code></pre><p>The script above creates LANCE-formatted files for the training, testing, and validation sets of the CINIC-10 dataset</p><pre><code class="language-python"># Load the LANCE-formatted datasets
train = data_frames['train']
test = data_frames['test'] 
val = data_frames['val']
</code></pre><p>and The <code>data_frames</code> dictionary contains the Pandas DataFrames for the training, testing, and validation sets, where each DataFrame has the following structure:</p><pre><code class="language-markdown">   image                                              filename                    label    split
0  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  n02130308_1836.png           cat     train
1  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  cifar10-train-21103.png      cat     train
2  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  cifar10-train-44957.png      cat     train
3  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  n02129604_14997.png          cat     train
4  b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\...  n02123045_1463.png           cat     train
</code></pre><p>Now that we have the LANCE-formatted data ready, we can use it to train a Convolutional Neural Network (CNN) for image classification. To do this, we’ll first need to create PyTorch Dataset and DataLoader objects from the LANCE-formatted Pandas DataFrames.</p><h2 id="load-the-lance-files-to-create-the-dataloaders">Load the lance files to create the dataloaders</h2><p>When working with LANCE-formatted image data, we need to consider that the images are stored in a binary format within the Pandas DataFrame. To use this data with a Convolutional Neural Network (CNN), we need to convert the binary data back into a format that the CNN can process, such as PIL Image objects. Here’s how we we’ll do that:</p><ol><li>Retrieve the binary image data: The image data is stored in binary format within the Pandas DataFrame. We’ll need to extract this binary data for each image.</li><li>Convert to PIL Image: Once we have the binary data, we’ll convert it into a PIL Image object. This will give us a readable image format that we can work with.</li><li>Handle grayscale images: Some of the images might be in grayscale mode. We’ll need to convert these to RGB format so they’re compatible with a CNN that expects 3-channel color images.</li><li>Apply transformations: Before feeding the images to the CNN, we may need to apply some transformations, like resizing or normalization. We can do this using the provided transform function.</li><li>Determine the labels: Each image has a label or class associated with it. We’ll look up the class index for the image’s label in the provided list of classes.</li><li>Return the data: Finally, we’ll return the transformed image and its corresponding label, which can be used to train the CNN model.</li></ol><p>To accomplish this, we’ll create a custom PyTorch Dataset class that can handle the all the heavy lifting and give us this sweet dataset to work with</p><pre><code class="language-python">from torch.utils import data
from PIL import Image
import io

class CustomImageDataset(data.Dataset):
    def __init__(self, df, classes, transform=None):
        self.df = df
        self.classes = classes
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_data = self.df.iloc[idx]['image']
        img = Image.open(io.BytesIO(img_data))

        # Convert grayscale images to RGB
        if img.mode != 'RGB':
            img = img.convert('RGB')

        if self.transform:
            img = self.transform(img)

        label = self.classes.index(self.df.iloc[idx]['label'])
        return img, label
</code></pre><p>This custom dataset class handles all the necessary steps to prepare our LANCE-formatted dataframe for use with a CNN model. By using this class, you can easily integrate the LANCE data into your PyTorch-based training pipeline. oh boy, we are ready to roll for training our model.</p><h3 id="training-a-cnn">Training a CNN</h3><p>So we have written our custom dataset class, we will just import it in our main CNN script and utilize it’s functionalities, as it’s pretty easy now</p><p>First we will load our lance files, then we will convert those lance files to our pandas dataframe objects and then finally the customimagedataset to utilize the binary data of the images to give us this image dataset..</p><p>That’s it, other than that, it’s simple CNN network doing the training..</p><pre><code class="language-python">import torch 
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from custom_dataset import CustomImageDataset
import pandas as pd
import matplotlib.pyplot as plt
import lance
from tqdm import tqdm
import torch.optim as optim

# Define the classes
classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship', 'truck')

# Define the image transformations
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

def loading_into_pandas(uri):
    ds = lance.dataset(uri)

    # Accumulate data from batches into a list
    data = []
    for batch in tqdm(ds.to_batches(columns=["image", "filename", "label", "split"], batch_size=10), desc="Loading batches"):
        tbl = batch.to_pandas()
        data.append(tbl)

    # Concatenate all DataFrames into a single DataFrame
    df = pd.concat(data, ignore_index=True)
    print("Pandas DataFrame is ready")
    print("Total Rows: ", df.shape[0])
    return df

def train_model(train_loader, model, criterion, optimizer, device, num_epochs=10):
    model.to(device)  # Move model to the specified device
    for epoch in range(num_epochs):
        running_loss = 0.0
        for i, data in enumerate(train_loader, 0):
            # get the inputs; data is a list of [inputs, labels]
            inputs, labels = data[0].to(device), data[1].to(device)  # Move data to the specified device

            # zero the parameter gradients
            optimizer.zero_grad()
            
            # forward + backward + optimize
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if i % 64 == 63:  # Print every 64 mini-batches (batch size)
                print(f'[{epoch + 1}, {i + 1:2d}] loss: {running_loss / 64:.3f}')
                running_loss = 0.0

    print('Finished Training')

def main():
    if torch.backends.mps.is_available():
        device = torch.device("mps")
        print("MPS Device:", device)
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print("Device:", device)    

    # Load datasets
    training_df = loading_into_pandas('cinic/cinic_train.lance')
    testing_df = loading_into_pandas('cinic/cinic_test.lance')
    validation_df = loading_into_pandas('cinic/cinic_val.lance')

    # Create datasets
    train_dataset = CustomImageDataset(training_df, classes, transform=transform)
    test_dataset = CustomImageDataset(testing_df, classes, transform=transform)
    val_dataset = CustomImageDataset(validation_df, classes, transform=transform)

    # Create data loaders
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)

    # Define the neural network
    class Net(nn.Module):
        def __init__(self):
            super(Net, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5) # 3 input channels, 6 output channels, 5x5 kernel
            self.pool = nn.MaxPool2d(2, 2) # 2x2 pooling
            self.conv2 = nn.Conv2d(6, 16, 5) # 6 input channels, 16 output channels, 5x5 kernel
            self.fc1 = nn.Linear(16 * 5 * 5, 120) 
            self.fc2 = nn.Linear(120, 84) 
            self.fc3 = nn.Linear(84, 10) # There are 10 classes

        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = torch.flatten(x, 1) # flatten all dimensions except batch
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x

    # Instantiate the model
    net = Net()

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

    # Train the model
    train_model(train_loader, net, criterion, optimizer, device, num_epochs=10)

    PATH = './cinic_net.pth'
    torch.save(net.state_dict(), PATH)

    net = Net()
    net.load_state_dict(torch.load(PATH))

    correct = 0
    total = 0

    # since we're not training, we don't need to calculate the gradients for our outputs
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            # calculate outputs by running images through the network
            outputs = net(images)
            # the class with the highest energy is what we choose as prediction
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    # Calculate accuracy
    accuracy = 100 * correct / total
    print('Accuracy of the network on the test images: %.2f %%' % accuracy)

if __name__ == "__main__":
    main()

</code></pre><p>We’ve just wrapped up training a Convolutional Neural Network (CNN) with a dataset of lance images with just a single script.</p><p>And if you are Curious about why Lance-backed training outperforms our vanilla approaches? I’ve got a <a href="https://wandb.ai/vipulmaheshwari/cinic-10/reports/CINIC-10-CNN-Training-Showdown-Lance-Vs-Vanilla--Vmlldzo3NTQxMTY5?accessToken=k2tk2e7u6x4ya5vivhtzieoh3lzm25e5z1inqhmaue41prct5ca65xufi3eznhj4">report</a> for you, showcasing how Lance-backed training excels in terms of I/O operations and training epochs compared to traditional methods.</p><p>By the way, you can dive into various deep learning techniques that utilize lance-formatted data on this <a href="https://github.com/lancedb/lance-deeplearning-recipes">repository</a></p><span class="meta"><time datetime="2024-04-10T00:00:00+05:30">April 10, 2024</time> &middot; <a href="/tag/Lance">Lance</a>, <a href="/tag/Dataset">Dataset</a></span>--> <!--</section>--></main><script async src="https://www.googletagmanager.com/gtag/js?id=G-JBZRCCYMBP"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-JBZRCCYMBP'); </script></body></html>
