<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="Understanding RAG fusion" /><meta property="og:locale" content="en_US" /><meta name="description" content="This post gives an adequate understanding of how the RAG fusion works." /><meta property="og:description" content="This post gives an adequate understanding of how the RAG fusion works." /><link rel="canonical" href="http://localhost:4000/2024/12/25/rag-fusion-understanding" /><meta property="og:url" content="http://localhost:4000/2024/12/25/rag-fusion-understanding" /><meta property="og:site_name" content="Deox Labs" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-12-25T00:00:00+05:30" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Understanding RAG fusion" /><meta name="twitter:site" content="@fuxssss" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-12-25T00:00:00+05:30","datePublished":"2024-12-25T00:00:00+05:30","description":"This post gives an adequate understanding of how the RAG fusion works.","headline":"Understanding RAG fusion","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/12/25/rag-fusion-understanding"},"url":"http://localhost:4000/2024/12/25/rag-fusion-understanding"}</script><title> Understanding RAG fusion - Deox Labs</title><link rel="shortcut icon" href="/favicon.png"><link rel="alternate" type="application/atom+xml" title="Deox Labs" href="/atom.xml"><link rel="alternate" type="application/json" title="Deox Labs" href="http://localhost:4000/feed.json" /><link rel="sitemap" type="application/xml" title="sitemap" href="/sitemap.xml" /><style> *,:after,:before{box-sizing:border-box;background-color:inherit;color:inherit;margin:0;padding:0}body{font-family:system-ui,sans-serif;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;line-height:1.5;font-size:1rem;color:#16171a}nav ul{border-right:1px solid #edf2f7}a{color:#000;text-decoration-skip-ink:auto;text-decoration:underline}pre{margin:.5rem 0;padding:.5rem}.post p{margin:.5rem 0}.post h1,.post h2,.post h3,.post h4{margin:1rem 0}.post h2:first-child,.project h2:first-child,.photo h2:first-child{margin-top:0}.meta{margin:2rem 0}code,pre{background:#f5f5f5;max-width:100%;overflow-x:auto}code{padding:.1rem;font-size:.85rem}pre code{border:none}pre{padding:1rem;overflow-x:auto}img{max-width:100%;background:none;display:block;margin:auto}hr{background:#000;height:1px;border:0}header{flex-basis:10rem;flex-grow:1;position:relative}header a{text-decoration:none}header li{margin-bottom:.2rem;text-align:right;margin-right:2rem}header a.active{font-weight:bold}header,section{padding:1rem}blockquote{font-style:italic;border-left:5px solid #ececec;padding-left:1rem}h1,h2,h3,h4,h5{line-height:1;margin:1rem 0;font-weight:600}section h1:first-child{margin-top:0}strong,b{font-weight:bold}.photos ul{list-style:none}.photos li{margin-bottom:1.5rem}.photo picture,.project picture{margin-bottom:.5rem}.posts ul,header ul{list-style:none}.posts li{align-items:center;display:flex;justify-content:space-between;margin-bottom:.5rem}.posts li a,.posts li div,.projects li a{white-space:nowrap;overflow:hidden;text-overflow:ellipsis;text-decoration:none}.posts li time,.projects li time{padding-left:1rem;white-space:nowrap;font-variant-numeric:tabular-nums}.post ol,.project ul,.post ol,.post ul{padding-left:1rem}main{display:flex;flex-wrap:wrap;max-width:60rem;margin:2rem auto;padding:1rem}@media screen and (max-width: 45rem){header li{display:inline;margin-right:1rem}.logo{padding-bottom:1rem}header ul{border-bottom:1px solid #edf2f7;padding-bottom:2rem}nav ul{border-right:0px}.photos ul{margin-top:.5rem}}section{flex-basis:0;flex-grow:999;min-width:70%;display:flex;flex-direction:column}figcaption{font-size:smaller}@media print{.no-print,.no-print *{display:none !important}}.back-to-top{position:fixed;bottom:20px;right:20px;background-color:#fff;color:#000;padding:10px;text-decoration:none;border-radius:5px;display:block;margin-right:20%}</style></head><body><main><header aria-hidden="true" class="no-print"> <!--<h1 class="logo">Deox Labs</h1>--><nav role="navigation" aria-hidden="true"><ul><li><a href="/" >Home</a></li><li><a href="/about" >About</a></li><li><a href="/contact" >Contact</a></li><li><a href="/projects" >Projects</a></li></ul></nav></header><section class="post"><h1>Understanding RAG fusion</h1><p>If you don’t have any clue on what RAG is, please go through this <a href="https://vipul-maheshwari.github.io/2024/02/14/rag-application-with-langchain">one</a> to get a brief on what this is all about.</p><p>So when the RAG model ends, RAG Fusion picks up by adding more layers that improve the RAG retrieval phase, particularly by adding more sophisticated mechanisms for interpretation and integration of the retrieval output. RAG Fusion tries to combat some of the weaknesses inherent also to RAG, including better response to ambiguous queries and returning more relevant, accurate information by improving the retrieval-to-generation loop.</p><h2 id="what-was-missed-in-rag">What was missed in RAG?</h2><ol><li>Constraints with Current Search Technologies: RAG is limited by the same things limiting our retrieval-based lexical and vector search technologies.</li><li>Human Search Inefficiencies: Humans are not great at writing what they want into search systems, such as typos, vague queries, or limited vocabulary, which often lead to missing the vast reservoir of information that lies beyond the obvious top search results. While RAG assists, it hasn’t entirely solved this problem.</li><li>Over-Simplification of Search: Our prevalent search paradigm linearly maps queries to answers, lacking the depth to understand the multi-dimensional nature of human queries. This linear model often fails to capture the nuances and contexts of more complex user inquiries, resulting in less relevant results.</li></ol><h2 id="how-the-improvement-really-happens">How the improvement really happens?</h2><p>So basically when we talk about the traditional RAG, it works by ranking documents in the order of relevance to the query based on vector similarity distances, usually using cosine similarity.</p><p>RAG Fusion on the other hands addresses the challenges of document retrieval using</p><ol><li>Query Transformation: Generates multiple new queries from different angels based on the original query and</li><li>Reciprocal Rank Fusion(RRF): Reranking the document relevance based on Reciprocal Rank Fusion(RRF)</li></ol><p>That being said, when RAG Fusion receives the original query, it sends the original query to the large language model(LLM) to generate a number of new search queries based on the original query from different perspectives.</p><p>So what really happens is</p><ol><li>Query Duplication with a Twist: Translate a user’s query into similar, yet distinct queries via an LLM.</li><li>Vector Search Unleashed: Perform vector searches for the original and its newly generated query siblings.</li><li>Intelligent Reranking: Aggregate and refine all the results using reciprocal rank fusion.</li><li>Final Step: Pair the cherry-picked results with the new queries, guiding the large language model to a crafted output that considers all the queries and the reranked list of results.</li></ol><p>Now For all the documents retrieved from the vector database for each query, like a list of lists.</p><ul><li>Determine the rank of each document within its respective ranked list.</li><li>For each document, compute the reciprocal of its rank (e.g., rank 1 → 1/1 = 1; rank 3 → 1/3).</li><li>Sum the reciprocal ranks of each retrieved document across all generated queries.</li><li>Order the documents based on their total aggregated scores to determine their final ranking.</li></ul><p>And then now the top-ranked retrieved documents will be then sent to the LLM along with all the queries to generate a response.</p><span class="meta"><time datetime="2024-12-25T00:00:00+05:30">December 25, 2024</time></span></section><!-- --- layout: default ---<section class="post"><h2>Understanding RAG fusion</h2><p>If you don’t have any clue on what RAG is, please go through this <a href="https://vipul-maheshwari.github.io/2024/02/14/rag-application-with-langchain">one</a> to get a brief on what this is all about.</p><p>So when the RAG model ends, RAG Fusion picks up by adding more layers that improve the RAG retrieval phase, particularly by adding more sophisticated mechanisms for interpretation and integration of the retrieval output. RAG Fusion tries to combat some of the weaknesses inherent also to RAG, including better response to ambiguous queries and returning more relevant, accurate information by improving the retrieval-to-generation loop.</p><h2 id="what-was-missed-in-rag">What was missed in RAG?</h2><ol><li>Constraints with Current Search Technologies: RAG is limited by the same things limiting our retrieval-based lexical and vector search technologies.</li><li>Human Search Inefficiencies: Humans are not great at writing what they want into search systems, such as typos, vague queries, or limited vocabulary, which often lead to missing the vast reservoir of information that lies beyond the obvious top search results. While RAG assists, it hasn’t entirely solved this problem.</li><li>Over-Simplification of Search: Our prevalent search paradigm linearly maps queries to answers, lacking the depth to understand the multi-dimensional nature of human queries. This linear model often fails to capture the nuances and contexts of more complex user inquiries, resulting in less relevant results.</li></ol><h2 id="how-the-improvement-really-happens">How the improvement really happens?</h2><p>So basically when we talk about the traditional RAG, it works by ranking documents in the order of relevance to the query based on vector similarity distances, usually using cosine similarity.</p><p>RAG Fusion on the other hands addresses the challenges of document retrieval using</p><ol><li>Query Transformation: Generates multiple new queries from different angels based on the original query and</li><li>Reciprocal Rank Fusion(RRF): Reranking the document relevance based on Reciprocal Rank Fusion(RRF)</li></ol><p>That being said, when RAG Fusion receives the original query, it sends the original query to the large language model(LLM) to generate a number of new search queries based on the original query from different perspectives.</p><p>So what really happens is</p><ol><li>Query Duplication with a Twist: Translate a user’s query into similar, yet distinct queries via an LLM.</li><li>Vector Search Unleashed: Perform vector searches for the original and its newly generated query siblings.</li><li>Intelligent Reranking: Aggregate and refine all the results using reciprocal rank fusion.</li><li>Final Step: Pair the cherry-picked results with the new queries, guiding the large language model to a crafted output that considers all the queries and the reranked list of results.</li></ol><p>Now For all the documents retrieved from the vector database for each query, like a list of lists.</p><ul><li>Determine the rank of each document within its respective ranked list.</li><li>For each document, compute the reciprocal of its rank (e.g., rank 1 → 1/1 = 1; rank 3 → 1/3).</li><li>Sum the reciprocal ranks of each retrieved document across all generated queries.</li><li>Order the documents based on their total aggregated scores to determine their final ranking.</li></ul><p>And then now the top-ranked retrieved documents will be then sent to the LLM along with all the queries to generate a response.</p><span class="meta"><time datetime="2024-12-25T00:00:00+05:30">December 25, 2024</time> &middot; <a href="/tag/RAG">RAG</a>, <a href="/tag/LanceDB">LanceDB</a>, <a href="/tag/RAG Fusion">RAG Fusion</a>, <a href="/tag/Improvement in RAG">Improvement in RAG</a></span>--> <!--</section>--></main><script async src="https://www.googletagmanager.com/gtag/js?id=G-JBZRCCYMBP"></script> <script> window.dataLayer = window.dataLayer || []; function gtag() { dataLayer.push(arguments); } gtag('js', new Date()); gtag('config', 'G-JBZRCCYMBP'); </script></body></html>
