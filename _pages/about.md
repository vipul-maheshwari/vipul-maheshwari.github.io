---
layout: page
title: About
---

I’m Vipul Maheshwari from Bharat, and I did my B.Tech in Computer Science.

My journey into the world of Artificial Intelligence and Deep Learning began in my second year when a senior student of mine was working on a classified project for the Indian Army. I volunteered in that project and I was tasked with object localization and creating a manual test set using bounding boxes. The project was a huge success, and it immediately grabbed my attention. I was amazed at how a blend of linear algebra, computational resources, and a dash of Python could work wonders.

Following that project, I embarked on a research apprenticeship with one of my professors. Our research focused on creating unified model predictors for neurological diseases. We delved into neuroimaging data related to Impulse Control Disorder (ICD) and developed an LSTM synthesizer capable of predicting the deterioration levels of patients. This research grabbed the attention of reviewers at ICICV, and we bagged the Best Paper Award.

Moving on, I had the opportunity to intern with an incredible AI company as a computer vision practitioner. During this internship, I utilized YOLO, image slicing, and segmentation algorithms to build impressive machine learning pipelines for a wide range of tasks.

Soon after this internship, I joined an AI company specializing in the creation of multilingual AI bots using deep learning algorithms as an NLP Deep Learning Intern. My role involved resolving numerous multilingual Natural Language Understanding (NLU) and Named Entity Recognition (NER) challenges for over 15 clients. I implemented NER entity extraction using rule-based regex and pattern dictionaries to enhance intent coverage. Additionally, I improved and refactored the Python scripts for NER data creation and the multilingual NLU code base for production-level NLP applications. I also conducted extensive tests on knowledge distillation, where I demonstrated the use of transfer learning to decrease the latency of production models and the usage of Large Language Models (LLMs) in large-scale conversational AI.

Now comes the time when I am moving to the big leagues.


First comes Endeavor Labs, a research lab / consultancy firm based in NY. 

At Endeavor Labs, I contributed to a supervised core machine learning project, developing robust classification models using gradient-based optimization techniques and advanced feature engineering to enhance predictive accuracy across diverse datasets. I also designed and implemented an OCR and NLP-based invoice processing system, leveraging Tesseract for optical character recognition and transformer-based NLP models, such as BERT, for entity extraction and semantic parsing. This system automated the extraction of structured data from unstructured invoices, utilizing custom tokenization pipelines and contextual embeddings to improve processing efficiency and accuracy.

well moving ahead, it was my time to become founding engineer at Bolna.

At Bolna, I contributed to building innovative AI solutions, focusing on cascaded voice AI architectures and fine-tuning text-to-speech (TTS) models for Indic languages. It was a short haul but full of amazing challenges.

Pheww, Now comes the LanceDB. 

So I served as a Machine Learning Consultant at LanceDB, where I worked on multimodal Retrieval-Augmented Generation (RAG), deep learning using Lance dataloaders, and the Lancify package to convert images to Lance dataloaders, enabling efficient data pipelines for vision-based applications.

Additionally, here and there, I collaborated with consulting companies such as Figr, Arrowhead, and Superlinked. At Figr, I worked on zero-shot and few-shot learning approaches to generate Figma components for text-to-Figma code, contributing to a custom library for Figma using generative AI techniques.

Currently, I am working with Juspay, where I am developing advanced AI systems focused on semantic search, information retrieval, and agent-based architectures. My work involves designing and implementing end-to-end Retrieval-Augmented Generation (RAG) pipelines, optimizing vector search for low-latency query processing, and building intelligent agent creation and calling frameworks. These efforts leverage state-of-the-art transformer models and knowledge graphs to enhance contextual understanding and scalability in production-grade AI applications.

If you’re looking to collaborate on a project related to AI or ML, feel free to reach out—I’m just a message away! Connect with me on LinkedIn for more details.
